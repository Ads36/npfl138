### Assignment: ddim_attention
#### Date: Deadline: Jun 28, 22:00
#### Points: 1 points
#### Examples: ddim_attention_examples

This task is an extension of the `ddim` assignment. Your goal is
to extend the original architecture with self-attention blocks,
which are used only in some number of lower-resolution stages.

Start with the `ddim_attention.py` template (to be released soon), where most of the comments come already from the `ddim` assignments.
Again, the template generate images to TensorBoard, and the images generated by
the reference solution can be also seen in the Examples.

#### Examples Start: ddim_attention_examples
_Note that your results may be slightly different, depending on your CPU type and whether you use a GPU._
- `python3 ddim_attention.py --dataset=oxford_flowers102 --epochs=70 --plot_each=10`
![oxford_flowers102 samples](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2324/demos/ddim_attention-oxford_flowers102.webp)
- `python3 ddim_attention.py --dataset=lsun_bedrooms --epochs=100 --plot_each=10`
![lsun_bedrooms samples](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2324/demos/ddim_attention-lsun_bedrooms.webp)
- `python3 ddim_attention.py --dataset=ffhq --epochs=100 --plot_each=10`
![ffhq samples](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2324/demos/ddim_attention-ffhq.webp)
#### Examples End:
